---
title: "Articulo 3: Naive-Bayes"
authors:
  - name: Jorge Nevarez - A01645313
  - name: Alfredo Lopez - A01638976
  - name: Damian Luna - A01645865
  - name: Diana Hernandez - A01639515
format: html
editor: visual
---

```{r}
#Setup global cargando librerias y nuestra base de datos
set.seed(1234)
install.packages("tidytext")
library(tidyverse)
library(tidymodels)
library(tidytext)
library(stringr)
library(ggplot2)
library(tidyr)
library(Matrix)
library(e1071)

data <- read_csv("data/stories.csv")
head(data)
```

✏️ Realicen un pequeño análisis de texto utilizando la base de datos que scrapearon. La actividad de Mine sobre text mining les puede dar ideas y el código necesario para realizar este análisis.

```{r}
data_clean <- data %>%
  mutate(Description = str_to_lower(Description)) %>%
  mutate(Description = str_replace_all(Description, "[[:punct:]]", " ")) %>%
  mutate(Description = str_squish(Description))
```

### **Tokenización y remoción de stopwords**

```{r}
tokens <- data_clean %>%
  unnest_tokens(word, Description) %>%
  anti_join(stop_words, by = "word")
```

### **Frecuencia de palabras**

```{r}
top_words <- tokens %>%
  count(word, sort = TRUE) %>%
  slice_max(n, n = 20)

top_words
```

### **Visualización**

```{r}
top_words %>%
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Top 20 palabras en relatos",
       x = "Palabra", y = "Frecuencia") +
  theme_minimal()
```

✏️ Construyan una sparse matrix que incluya la frecuencia de cada palabra en los relatos scrapeados, donde cada renglón representa un relato diferente y donde las columnas son las diferentes palabras. Esta matriz también debe contener el tipo de evento paranormal. La función unnest_tokens() les puede ayudar. Consideren eliminar las palabras comunes en inglés a través de las stop words. Todo este proceso se conoce como un count vectorizer, que significa transformar texto a vectores.

```{r}
dtm_long <- tokens %>%
  count(ID, word, name = "freq")

dtm_wide <- dtm_long %>%
  pivot_wider(
    names_from = word,
    values_from = freq,
    values_fill = 0
  ) %>%
  left_join(data %>% select(ID, Category) %>% distinct(), by = "ID")

```

```{r}
# Matriz dispersa y vector de etiquetas
X_sparse <- dtm_long %>%
  cast_sparse(row = ID, column = word, value = freq)

id_order <- as.integer(rownames(X_sparse))
y <- data %>%
  distinct(ID, Category) %>%
  arrange(match(ID, id_order)) %>%
  pull(Category)
```

```{r}
dim(dtm_wide)       # filas = relatos, columnas = palabras + Category
head(dtm_wide[, 1:10])  # primeras columnas para ver conteos

X_sparse            # resumen de la matriz dispersa
length(y)           # debe coincidir con nrow(X_sparse)
head(y)             # primeras etiquetas
```

```{r}
# asegurarse de tener X_sparse ya creado y data disponible
# recuperar el orden de IDs que usa la matriz dispersa
id_order <- as.integer(rownames(X_sparse))

# crear un data.frame con la etiqueta original y ordenarlo para que
# coincida con las filas de X_sparse
label_df <- data %>%
  distinct(ID, Category) %>%
  mutate(Category = str_squish(Category)) %>%
  arrange(match(ID, id_order))

# crear etiqueta binaria (case_when). Cambia el patrón si quieres otro criterio.
label_df <- label_df %>%
  mutate(Category_bin = case_when(
    str_detect(Category, regex("Haunted Places", ignore_case = TRUE)) ~ "Haunted",
    TRUE ~ "Other"
  ))

# vector factor alineado con filas de X_sparse
y_binary <- factor(label_df$Category_bin, levels = c("Haunted", "Other"))

# comprobación rápida
stopifnot(length(y_binary) == nrow(X_sparse))
table(y_binary)   # ver distribución de clases
```

```{r}
# frecuencia por término (número de documentos donde aparece)
term_df <- colSums(X_sparse > 0)
min_df <- 5        # ajustar según memoria/velocidad
keep_terms <- which(term_df >= min_df)

X_sparse_reduced <- X_sparse[, keep_terms]
dim(X_sparse_reduced)
```

✏️ Dividan la matriz de datos en training y test set. Y utilicen el training set para entrenar un clasificador naïve Bayes para predecir el tipo de evento paranormal.

```{r}
set.seed(1234)
n <- nrow(X_sparse_reduced)   # o X_sparse si no redujiste
idx <- sample(seq_len(n), size = floor(0.7 * n))

X_train <- X_sparse_reduced[idx, ]
X_test  <- X_sparse_reduced[-idx, ]

y_train <- y_binary[idx]
y_test  <- y_binary[-idx]
```

✏️ La clasificación multiclase impone un mayor desafío, para facilitar las cosas dicotomizaremos el tipo de evento paranormal. Con ayuda de la función case_when() pueden recodificar el tipo de evento paranormal, por ejemplo, si es Haunted Places u Other. ✏️ Intenten utilizar la función naive_bayes() del paquete naivebayes para volver a ajustar su clasificador, ¿existe alguna diferencia?

### Modelo 1: libreria e1071

```{r}
NB_e1071 <- naiveBayes(x = as.matrix(X_train), y = y_train)

# predecir
pred_e1071 <- predict(NB_e1071, as.matrix(X_test))
```

```{r}
conf_mat <- table(Actual = y_test, Predicted = pred_e1071)
conf_mat

TP <- sum(y_test == "Haunted" & pred_e1071 == "Haunted")
TN <- sum(y_test == "Other"   & pred_e1071 == "Other")
FP <- sum(y_test == "Other"   & pred_e1071 == "Haunted")
FN <- sum(y_test == "Haunted" & pred_e1071 == "Other")

accuracy  <- (TP + TN) / (TP + TN + FP + FN)
precision <- ifelse((TP + FP) > 0, TP / (TP + FP), 0)
recall    <- ifelse((TP + FN) > 0, TP / (TP + FN), 0)
f1        <- ifelse((precision + recall) > 0, 2 * precision * recall / (precision + recall), 0)

metrics_df <- tibble(
  Metric = c("Accuracy", "Precision (Haunted)", "Recall (Haunted)", "F1 (Haunted)"),
  Value  = c(accuracy, precision, recall, f1)
)
metrics_df
```

✏️ Vuelvan a entrenar un clasificador naïve Bayes con ambas funciones, ¿hubo alguna mejora?

```{r}
library(naivebayes)
```

###Modelo 2: libreria naivebayes

```{r}

NB_nb <- naive_bayes(x = as.matrix(X_train), y = y_train)
pred_nb <- predict(NB_nb, as.matrix(X_test))
```

```{r}
# métricas para naivebayes
conf_mat <- table(Actual = y_test, Predicted = pred_nb)
conf_mat

TP2 <- sum(y_test == "Haunted" & pred_nb == "Haunted")
TN2 <- sum(y_test == "Other"   & pred_nb == "Other")
FP2 <- sum(y_test == "Other"   & pred_nb == "Haunted")
FN2 <- sum(y_test == "Haunted" & pred_nb == "Other")

accuracy2  <- (TP2 + TN2) / (TP2 + TN2 + FP2 + FN2)
precision2 <- ifelse((TP2 + FP2) > 0, TP2 / (TP2 + FP2), 0)
recall2    <- ifelse((TP2 + FN2) > 0, TP2 / (TP2 + FN2), 0)
f12        <- ifelse((precision2 + recall2) > 0, 2 * precision2 * recall2 / (precision2 + recall2), 0)

comparison <- tibble(
  Model = c("e1071::naiveBayes", "naivebayes::naive_bayes"),
  Accuracy = c(accuracy, accuracy2),
  Precision = c(precision, precision2),
  Recall = c(recall, recall2),
  F1 = c(f1, f12)
)
comparison
```

✏️ Un problema que enfrentan estas primeras implementaciones del clasificador naïve Bayes es el supuesto de la distribución normal para los nodos hijo. Este supuesto parece poco pertinente en este caso debido a que lo que contiene nuestra matriz de datos son en realidad conteos. La distribución Poisson resulta una mejor alternativa para este tipo de datos. Pueden utilizar esta distribución en la función naive_bayes() del paquete naivebayes mediante el argumento usepoisson = TRUE.
### Usando la libreria naivebayes vamos a usar una distribución Poisson 
Primero convertimos las matrices a df para que todas las columnas sean int

```{r}
# Convertir sparse a dense
X_train_dense <- as.matrix(X_train)
X_test_dense  <- as.matrix(X_test)

# Convertir a data.frame de enteros
X_train_df <- as.data.frame(apply(X_train_dense, 2, as.integer))
X_test_df  <- as.data.frame(apply(X_test_dense, 2, as.integer))

```

Entrenamos el modelo con poisson
```{r}
# Entrenar NB Poisson 
NB_poisson <- naive_bayes(
  x = X_train_df,
  y = y_train,
  usepoisson = TRUE
)

pred_poisson <- predict(NB_poisson, X_test_df)
```

```{r}
# métricas para poisson
conf_mat3 <- table(Actual = y_test, Predicted = pred_poisson)
conf_mat3

TP3 <- sum(y_test == "Haunted" & pred_poisson == "Haunted")
TN3 <- sum(y_test == "Other"   & pred_poisson == "Other")
FP3 <- sum(y_test == "Other"   & pred_poisson == "Haunted")
FN3 <- sum(y_test == "Haunted" & pred_poisson == "Other")

accuracy3  <- (TP3 + TN3) / (TP3 + TN3 + FP3 + FN3)
precision3 <- ifelse((TP3 + FP3) > 0, TP3 / (TP3 + FP3), 0)
recall3    <- ifelse((TP3 + FN3) > 0, TP3 / (TP3 + FN3), 0)
f13        <- ifelse((precision3 + recall3) > 0, 2 * precision3 * recall3 / (precision3 + recall3), 0)

comparison <- tibble(
  Model = c("e1071::naiveBayes", "naivebayes::naive_bayes", "naivebayes::Poisson"),
  Accuracy = c(accuracy, accuracy2, accuracy3),
  Precision = c(precision, precision2, precision3),
  Recall = c(recall, recall2, recall3),
  F1 = c(f1, f12, f13)
)
comparison
```

Podmos ver que con Poisson mejor el modelo, sin embargo nos da muchos warnings por los datos en 0


### Usando suavizamiento de Laplace

```{r}
# Entrenar NB Poisson con Laplace
NB_poisson_l <- naive_bayes(x = X_train_df, y = y_train, usepoisson = TRUE, laplace = 1.5)
pred_poisson_l <- predict(NB_poisson_l, X_test_df)
```

```{r}
# métricas para poisson
conf_mat4 <- table(Actual = y_test, Predicted = pred_poisson_l)
conf_mat4

TP4 <- sum(y_test == "Haunted" & pred_poisson_l == "Haunted")
TN4 <- sum(y_test == "Other"   & pred_poisson_l == "Other")
FP4 <- sum(y_test == "Other"   & pred_poisson_l == "Haunted")
FN4 <- sum(y_test == "Haunted" & pred_poisson_l == "Other")

accuracy4  <- (TP4 + TN4) / (TP4 + TN4 + FP4 + FN4)
precision4 <- ifelse((TP4 + FP4) > 0, TP4 / (TP4 + FP4), 0)
recall4    <- ifelse((TP4 + FN4) > 0, TP4 / (TP4 + FN4), 0)
f14        <- ifelse((precision4 + recall4) > 0, 2 * precision4 * recall4 / (precision4 + recall4), 0)

comparison <- tibble(
  Model = c("e1071::naiveBayes", "naivebayes::naive_bayes", "naivebayes::Poisson", "naivebayes::Poisson_Laplace"),
  Accuracy = c(accuracy, accuracy2, accuracy3, accuracy4),
  Precision = c(precision, precision2, precision3, precision4),
  Recall = c(recall, recall2, recall3, recall4),
  F1 = c(f1, f12, f13, f14)
)
comparison
```
Vemos que con el suavizado de laplace ya no tenemos los warnings, pero empeoro un poco nuestro modelo, podemos usar cross validation para encontrar el mejor lambda para nuestro modelo con Poisson y Laplace

### Cross validation para encontrar el mejor valor de lambda


```{r}
#Instalamos y llamamos librerias necesarias
#install.packages("caret")
#install.packages("purr")
library(naivebayes)
library(caret)
library(dplyr)
library(purrr)
```

```{r}
# Definir los valores de lambda a probar
laplace_vals <- seq(0.1, 2, by = 0.1)

# Folds 10
folds <- createFolds(y_train, k = 2, list = TRUE)

# Función para entrenar y evaluar NB Poisson con un laplace dado
cv_nb_poisson <- function(lambda) {
  acc_folds <- map_dbl(folds, function(idx) {
    X_val <- X_train_df[idx, ]
    y_val <- y_train[idx]
    X_tr  <- X_train_df[-idx, ]
    y_tr  <- y_train[-idx]
    
    model <- naive_bayes(x = X_tr, y = y_tr, usepoisson = TRUE, laplace = lambda)
    pred  <- predict(model, X_val)
    
    mean(pred == y_val)  # Accuracy en este fold
  })
  
  mean(acc_folds)  # Accuracy promedio de los 10 folds
}

# Evaluar todos los valores de laplace
cv_results <- map_dbl(laplace_vals, cv_nb_poisson)

# Mejor lambda
best_lambda <- laplace_vals[which.max(cv_results)]
best_lambda
cv_results_df <- tibble(
  Laplace = laplace_vals,
  Accuracy = cv_results
)
cv_results_df

```


```{r}
# Entrenar NB Poisson con Laplace
NB_poisson_l <- naive_bayes(x = X_train_df, y = y_train, usepoisson = TRUE, laplace = 0.2)
pred_poisson_l <- predict(NB_poisson_l, X_test_df)
# métricas para poisson
conf_mat4 <- table(Actual = y_test, Predicted = pred_poisson_l)
conf_mat4

TP4 <- sum(y_test == "Haunted" & pred_poisson_l == "Haunted")
TN4 <- sum(y_test == "Other"   & pred_poisson_l == "Other")
FP4 <- sum(y_test == "Other"   & pred_poisson_l == "Haunted")
FN4 <- sum(y_test == "Haunted" & pred_poisson_l == "Other")

accuracy4  <- (TP4 + TN4) / (TP4 + TN4 + FP4 + FN4)
precision4 <- ifelse((TP4 + FP4) > 0, TP4 / (TP4 + FP4), 0)
recall4    <- ifelse((TP4 + FN4) > 0, TP4 / (TP4 + FN4), 0)
f14        <- ifelse((precision4 + recall4) > 0, 2 * precision4 * recall4 / (precision4 + recall4), 0)

comparison <- tibble(
  Model = c("e1071::naiveBayes", "naivebayes::naive_bayes", "naivebayes::Poisson", "naivebayes::Poisson_Laplace"),
  Accuracy = c(accuracy, accuracy2, accuracy3, accuracy4),
  Precision = c(precision, precision2, precision3, precision4),
  Recall = c(recall, recall2, recall3, recall4),
  F1 = c(f1, f12, f13, f14)
)
comparison
```

Podemos ver que haciendo cross validation con un k=2, nos dice que el mejor lambda es 0.2.
Viendo este resultado nos damos cuenta que no tiene la misma accuracy de poisson sin suvizamiento de Laplace,
pero si esta lo suficientemente cerca para poder decir que es mejor al quitar los errores de los valores en 0

 
