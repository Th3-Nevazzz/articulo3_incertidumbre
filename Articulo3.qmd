---
title: "Articulo 3: Naive-Bayes"
authors:
  - name: Jorge Nevarez - A01645313
  - name: Alfredo Lopez - A01638976
  - name: Damian Luna - A01645865
  - name: Diana Hernandez - A01639515
format: html
editor: visual
---

```{r}
#Setup global cargando librerias y nuestra base de datos
install.packages("tidytext")
library(tidyverse)
library(tidymodels)
library(tidytext)
library(stringr)
library(ggplot2)
library(tidyr)
library(Matrix)
library(e1071)

data <- read_csv("data/stories.csv")
head(data)
```

✏️ Realicen un pequeño análisis de texto utilizando la base de datos que scrapearon. La actividad de Mine sobre text mining les puede dar ideas y el código necesario para realizar este análisis.

```{r}
data_clean <- data %>%
  mutate(Description = str_to_lower(Description)) %>%
  mutate(Description = str_replace_all(Description, "[[:punct:]]", " ")) %>%
  mutate(Description = str_squish(Description))
```

### **Tokenización y remoción de stopwords**

```{r}
tokens <- data_clean %>%
  unnest_tokens(word, Description) %>%
  anti_join(stop_words, by = "word")
```

### **Frecuencia de palabras**

```{r}
top_words <- tokens %>%
  count(word, sort = TRUE) %>%
  slice_max(n, n = 20)

top_words
```

### **Visualización**

```{r}
top_words %>%
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Top 20 palabras en relatos",
       x = "Palabra", y = "Frecuencia") +
  theme_minimal()
```

✏️ Construyan una sparse matrix que incluya la frecuencia de cada palabra en los relatos scrapeados, donde cada renglón representa un relato diferente y donde las columnas son las diferentes palabras. Esta matriz también debe contener el tipo de evento paranormal. La función unnest_tokens() les puede ayudar. Consideren eliminar las palabras comunes en inglés a través de las stop words. Todo este proceso se conoce como un count vectorizer, que significa transformar texto a vectores.

```{r}
dtm_long <- tokens %>%
  count(ID, word, name = "freq")

dtm_wide <- dtm_long %>%
  pivot_wider(
    names_from = word,
    values_from = freq,
    values_fill = 0
  ) %>%
  left_join(data %>% select(ID, Category) %>% distinct(), by = "ID")

```

```{r}
# Matriz dispersa y vector de etiquetas
X_sparse <- dtm_long %>%
  cast_sparse(row = ID, column = word, value = freq)

id_order <- as.integer(rownames(X_sparse))
y <- data %>%
  distinct(ID, Category) %>%
  arrange(match(ID, id_order)) %>%
  pull(Category)
```

```{r}
dim(dtm_wide)       # filas = relatos, columnas = palabras + Category
head(dtm_wide[, 1:10])  # primeras columnas para ver conteos

X_sparse            # resumen de la matriz dispersa
length(y)           # debe coincidir con nrow(X_sparse)
head(y)             # primeras etiquetas
```

```{r}
# asegurarse de tener X_sparse ya creado y data disponible
# recuperar el orden de IDs que usa la matriz dispersa
id_order <- as.integer(rownames(X_sparse))

# crear un data.frame con la etiqueta original y ordenarlo para que
# coincida con las filas de X_sparse
label_df <- data %>%
  distinct(ID, Category) %>%
  mutate(Category = str_squish(Category)) %>%
  arrange(match(ID, id_order))

# crear etiqueta binaria (case_when). Cambia el patrón si quieres otro criterio.
label_df <- label_df %>%
  mutate(Category_bin = case_when(
    str_detect(Category, regex("Haunted Places", ignore_case = TRUE)) ~ "Haunted",
    TRUE ~ "Other"
  ))

# vector factor alineado con filas de X_sparse
y_binary <- factor(label_df$Category_bin, levels = c("Haunted", "Other"))

# comprobación rápida
stopifnot(length(y_binary) == nrow(X_sparse))
table(y_binary)   # ver distribución de clases
```

```{r}
# frecuencia por término (número de documentos donde aparece)
term_df <- colSums(X_sparse > 0)
min_df <- 5        # ajustar según memoria/velocidad
keep_terms <- which(term_df >= min_df)

X_sparse_reduced <- X_sparse[, keep_terms]
dim(X_sparse_reduced)
```

✏️ Dividan la matriz de datos en training y test set. Y utilicen el training set para entrenar un clasificador naïve Bayes para predecir el tipo de evento paranormal.

```{r}
set.seed(1234)
n <- nrow(X_sparse_reduced)   # o X_sparse si no redujiste
idx <- sample(seq_len(n), size = floor(0.7 * n))

X_train <- X_sparse_reduced[idx, ]
X_test  <- X_sparse_reduced[-idx, ]

y_train <- y_binary[idx]
y_test  <- y_binary[-idx]
```

✏️ La clasificación multiclase impone un mayor desafío, para facilitar las cosas dicotomizaremos el tipo de evento paranormal. Con ayuda de la función case_when() pueden recodificar el tipo de evento paranormal, por ejemplo, si es Haunted Places u Other. ✏️ Intenten utilizar la función naive_bayes() del paquete naivebayes para volver a ajustar su clasificador, ¿existe alguna diferencia?

### Modelo 1: libreria e1071

```{r}
NB_e1071 <- naiveBayes(x = as.matrix(X_train), y = y_train)

# predecir
pred_e1071 <- predict(NB_e1071, as.matrix(X_test))
```

```{r}
conf_mat <- table(Actual = y_test, Predicted = pred_e1071)
conf_mat

TP <- sum(y_test == "Haunted" & pred_e1071 == "Haunted")
TN <- sum(y_test == "Other"   & pred_e1071 == "Other")
FP <- sum(y_test == "Other"   & pred_e1071 == "Haunted")
FN <- sum(y_test == "Haunted" & pred_e1071 == "Other")

accuracy  <- (TP + TN) / (TP + TN + FP + FN)
precision <- ifelse((TP + FP) > 0, TP / (TP + FP), 0)
recall    <- ifelse((TP + FN) > 0, TP / (TP + FN), 0)
f1        <- ifelse((precision + recall) > 0, 2 * precision * recall / (precision + recall), 0)

metrics_df <- tibble(
  Metric = c("Accuracy", "Precision (Haunted)", "Recall (Haunted)", "F1 (Haunted)"),
  Value  = c(accuracy, precision, recall, f1)
)
metrics_df
```


✏️ Vuelvan a entrenar un clasificador naïve Bayes con ambas funciones, ¿hubo alguna mejora?

```{r}
library(naivebayes)
```


###Modelo 2: libreria naivebayes

```{r}

NB_nb <- naive_bayes(x = as.matrix(X_train), y = y_train)
pred_nb <- predict(NB_nb, as.matrix(X_test))
```

```{r}
# métricas para naivebayes
conf_mat <- table(Actual = y_test, Predicted = pred_nb)
conf_mat

TP2 <- sum(y_test == "Haunted" & pred_nb == "Haunted")
TN2 <- sum(y_test == "Other"   & pred_nb == "Other")
FP2 <- sum(y_test == "Other"   & pred_nb == "Haunted")
FN2 <- sum(y_test == "Haunted" & pred_nb == "Other")

accuracy2  <- (TP2 + TN2) / (TP2 + TN2 + FP2 + FN2)
precision2 <- ifelse((TP2 + FP2) > 0, TP2 / (TP2 + FP2), 0)
recall2    <- ifelse((TP2 + FN2) > 0, TP2 / (TP2 + FN2), 0)
f12        <- ifelse((precision2 + recall2) > 0, 2 * precision2 * recall2 / (precision2 + recall2), 0)

comparison <- tibble(
  Model = c("e1071::naiveBayes", "naivebayes::naive_bayes"),
  Accuracy = c(accuracy, accuracy2),
  Precision = c(precision, precision2),
  Recall = c(recall, recall2),
  F1 = c(f1, f12)
)
comparison
```

✏️ Un problema que enfrentan estas primeras implementaciones del clasificador naïve Bayes es el supuesto de la distribución normal para los nodos hijo. Este supuesto parece poco pertinente en este caso debido a que lo que contiene nuestra matriz de datos son en realidad conteos. La distribución Poisson resulta una mejor alternativa para este tipo de datos. Pueden utilizar esta distribución en la función naive_bayes() del paquete naivebayes mediante el argumento usepoisson = TRUE.

✏️ Otro problema que enfrentamos en este tipo de datos es que existen muchos ceros en la matriz de datos. Una posible solución es utilizar una técnica de suavizamiento conocida como Laplace smoothing. Investiguen sobre esta técnica e impleméntenla en su clasificador.

✏️ Como se habrán dado cuenta, puede ser arbitraria la selección de este parámetro, intenten realizar cross-validation para seleccionar el valor óptimo.
